[34m[1mdetect: [0mweights=['/media/nnthao/yolov5/runs/train/exp-mask/weights/last.pt'], source=/home/nnthao/project/FDA/test_sets/CelebA-HQ/masked_images/test1.png, data=data/coco128.yaml, imgsz=[512, 512], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1
YOLOv5 ðŸš€ v7.0-249-gf400bba Python-3.9.0 torch-2.1.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40337MiB)

Fusing layers... 
Model summary: 267 layers, 46189053 parameters, 0 gradients, 107.9 GFLOPs
image 1/1 /home/nnthao/project/FDA/test_sets/CelebA-HQ/masked_images/test1.png: 512x512 1 ear, 2 eyes, 1 nose, 1 mouth, 7.7ms
Speed: 0.2ms pre-process, 7.7ms inference, 1.4ms NMS per image at shape (1, 3, 512, 512)
Results saved to [1mruns/detect/exp[0m
None
